{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from data_loader import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class Logo2Font():\n",
    "    def __init__(self):        \n",
    "        # Input shape\n",
    "        self.img_rows = 256\n",
    "        self.img_cols = 256\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'font'\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "        # Build the edge conv\n",
    "        self.edge = self.get_edge()\n",
    "        self.edge.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer)\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generators\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator_r = self.build_generator()\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False  \n",
    "        self.edge.trainable = False \n",
    "        \n",
    "        # Input images and their conditioning images\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_Base = Input(shape=self.img_shape)\n",
    "        img_cycle = Input(shape=self.img_shape)\n",
    "\n",
    "        # By conditioning on A generate a fake version of B\n",
    "        fake_B = self.generator([img_A,img_Base])\n",
    "        re_A = self.generator_r([fake_B,img_cycle])\n",
    "        \n",
    "        # Get fake_B edge\n",
    "        edge_B = self.edge(fake_B)\n",
    "        \n",
    "        # Discriminators determines validity of Style condition / Content condition / Generate images \n",
    "        valid = self.discriminator([img_A, img_Base, fake_B])\n",
    "        \n",
    "        self.combined = Model(inputs=[img_A, img_Base, img_cycle], outputs=[valid, fake_B, edge_B, re_A])\n",
    "        self.combined.compile(loss=['mse', 'mae', 'mae','mae'],\n",
    "                              loss_weights=[10, 100, 100, 100],\n",
    "                              optimizer=optimizer)\n",
    "        \n",
    "        #Load LOGO tests\n",
    "        imgs, adidas_, huawei_, nike_  = self.data_loader.load_logo()\n",
    "        self.imgs = imgs\n",
    "        self.adidas_ = adidas_\n",
    "        self.huawei_ = huawei_\n",
    "        self.nike_ = nike_\n",
    "        \n",
    "    def build_generator(self):\n",
    "        \"\"\"DualInput U-Net Generator\"\"\"\n",
    "        \n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input,filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "        \n",
    "        def deconv2d_triple(layer_input, skip_input, baseconv, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input, baseconv])\n",
    "            return u\n",
    "        \n",
    "        # Image input\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_Base = Input(shape=self.img_shape)\n",
    "        \n",
    "        #combined_imgs = Concatenate(axis=-1)([img_A, img_Base])\n",
    "        \n",
    "        # Content Downsampling\n",
    "        c1 = conv2d(img_Base, self.gf, bn=False)\n",
    "        c2 = conv2d(c1, self.gf*2)\n",
    "        c3 = conv2d(c2, self.gf*4)\n",
    "        c4 = conv2d(c3, self.gf*8)\n",
    "        c5 = conv2d(c4, self.gf*8)\n",
    "        c6 = conv2d(c5, self.gf*8)\n",
    "        \n",
    "        \n",
    "        # Style Downsampling\n",
    "        s1 = conv2d(img_A, self.gf, bn=False)\n",
    "        s2 = conv2d(s1, self.gf*2)\n",
    "        s3 = conv2d(s2, self.gf*4)\n",
    "        s4 = conv2d(s3, self.gf*8)\n",
    "        s5 = conv2d(s4, self.gf*8)\n",
    "        s6 = conv2d(s5, self.gf*8)\n",
    "        s7 = conv2d(s6, self.gf*8)\n",
    "        \n",
    "        # Upsampling\n",
    "        u1 = deconv2d(s7, c6, self.gf*8)\n",
    "        u2 = deconv2d(u1, c5, self.gf*8)\n",
    "        u3 = deconv2d(u2, c4, self.gf*8)\n",
    "        u4 = deconv2d(u3, s3, self.gf*4)\n",
    "        u5 = deconv2d(u4, s2, self.gf*2)\n",
    "        u6 = deconv2d(u5, s1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "          \n",
    "        return Model([img_A,img_Base], output_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "        img_Base = Input(shape=self.img_shape)\n",
    "\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_Base, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A, img_Base, img_B], validity)\n",
    "    \n",
    "   \n",
    "    def get_edge(self):\n",
    "        img = Input(shape=self.img_shape)\n",
    "        kernel = np.array([(1,1,1,1),(1,-4,-2,1),(1,-2,-4,1),(1,1,1,1)])#边缘提取滤波卷积核\n",
    "        def gxl_kernel(shape):\n",
    "            return np.expand_dims(np.expand_dims(kernel, axis=2), axis=2)\n",
    "        img_edge = Conv2D(filters=1, kernel_size=4, kernel_initializer= gxl_kernel, strides=4, padding='same')(img)\n",
    "        \n",
    "        return Model(img, img_edge)\n",
    "\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "        # Load weights\n",
    "        if os.path.exists(\"logo2font_model_bf/G_dualmodelw175.hdf5\"):\n",
    "            self.generator.load_weights(\"logo2font_model_bf/G_dualmodelw175.hdf5\",by_name=True)\n",
    "            self.generator_r.load_weights(\"logo2font_model_bf/Gr_dualmodelw175.hdf5\",by_name=True)\n",
    "            self.discriminator.load_weights(\"logo2font_model_bf/D_dualmodelw175.hdf5\",by_name=True)\n",
    "            print(\"Load weights!!\")\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        \n",
    "        #记录训练数据用以画图\n",
    "        logs = []\n",
    "        dt_rate = 5\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B, imgs_Base, imgs_cycle) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "                \n",
    "                # -------------------------------\n",
    "                #  Train Discriminator 训练判别器\n",
    "                # -------------------------------\n",
    "\n",
    "                if batch_i % dt_rate == 0: #训练1次判别器，训练dt_rate次生成器\n",
    "                    # Conditions and generate a translated version\n",
    "                    fake_B = self.generator.predict([imgs_A, imgs_Base])\n",
    "                    \n",
    "                    # Train the discriminators (original images = real / generated = Fake)\n",
    "                    d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_Base, imgs_B], valid)\n",
    "                    d_loss_fake = self.discriminator.train_on_batch([imgs_A, imgs_Base, fake_B], fake)\n",
    "                    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                    \n",
    "                    #Set train rate \n",
    "                    if 100*d_loss[1] > 80:\n",
    "                        dt_rate += 1\n",
    "                    elif 100*d_loss[1] < 50 and dt_rate > 1:\n",
    "                        dt_rate -= 1\n",
    "\n",
    "                # ---------------------------------\n",
    "                #  Train Generators 训练循环生成器\n",
    "                # ---------------------------------\n",
    "                #imgs_A->B \n",
    "                B_edge = self.edge.predict(imgs_B)\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_Base, imgs_cycle], [valid, imgs_B, B_edge, imgs_A])\n",
    "                \n",
    "                \n",
    "                #imgs_B->A \n",
    "                A_edge = self.edge.predict(imgs_A)\n",
    "                gc_loss = self.combined.train_on_batch([imgs_B, imgs_cycle, imgs_Base], [valid, imgs_A, A_edge, imgs_B])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                \n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] [Gc loss: %f] time: %s\" % (epoch, epochs,\n",
    "                                                                        batch_i, self.data_loader.n_batches,\n",
    "                                                                        d_loss[0], 100*d_loss[1],\n",
    "                                                                        g_loss[0], \n",
    "                                                                        gc_loss[0],                                             \n",
    "                                                                        elapsed_time))\n",
    "                \n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)\n",
    "                \n",
    "                # save weight & model\n",
    "                if (epoch+9) % 10 == 0:\n",
    "                    epcnt = epoch \n",
    "                    if not os.path.exists(\"logo2font_model_bf\"):\n",
    "                        os.makedirs(\"logo2font_model_bf\")\n",
    "                    if not os.path.exists(\"logo2font_model_bf/G_dualmodelw%d.hdf5\" % epcnt):\n",
    "                        self.generator.save_weights(\"logo2font_model_bf/G_dualmodelw%d.hdf5\" % epcnt,True)\n",
    "                        self.generator_r.save_weights(\"logo2font_model_bf/Gr_dualmodelw%d.hdf5\" % epcnt,True)\n",
    "                        self.discriminator.save_weights(\"logo2font_model_bf/D_dualmodelw%d.hdf5\" % epcnt,True)\n",
    "                        \n",
    "                \n",
    "                if (epoch+9) % 15 == 0:\n",
    "                    epcnt = epoch\n",
    "                    if not os.path.exists(\"logo2font_model_bf/trained_model\"):\n",
    "                        os.makedirs(\"logo2font_model_bf/trained_model\")\n",
    "                    if not os.path.exists(\"logo2font_model_bf/trained_model/G_dmodel%d.hdf5\" % epcnt):\n",
    "                        self.generator.save(\"logo2font_model_bf/trained_model/G_dmodel%d.hdf5\" % epcnt,True)\n",
    "                        self.generator_r.save(\"logo2font_model_bf/trained_model/Gr_dmodel%d.hdf5\" % epcnt,True)\n",
    "                        self.discriminator.save(\"logo2font_model_bf/trained_model/D_dmodel%d.hdf5\" % epcnt,True)\n",
    "                        \n",
    "            logs.append([epoch, d_loss[0], d_loss[1], g_loss[0]])\n",
    "            self.showlogs(logs,epoch)                                      \n",
    "                \n",
    "\n",
    "    def sample_images(self, epoch, batch_i):\n",
    "        os.makedirs('images/%s_bf' % self.dataset_name, exist_ok=True)\n",
    "        os.makedirs('images/%s_bf_r' % self.dataset_name, exist_ok=True)\n",
    "        os.makedirs('images/%s_bf_adi' % self.dataset_name, exist_ok=True)\n",
    "        os.makedirs('images/%s_bf_nike' % self.dataset_name, exist_ok=True)\n",
    "        os.makedirs('images/%s_bf_huawei' % self.dataset_name, exist_ok=True)\n",
    "        os.makedirs('images/%s_bf_out' % self.dataset_name, exist_ok=True)\n",
    "        \n",
    "        r, c = 4, 3\n",
    "\n",
    "        imgs_A, imgs_B, imgs_Base, imgs_cycle = self.data_loader.load_data(batch_size=3, is_testing=True)\n",
    "        \n",
    "        #随机测试集\n",
    "        fake_B = self.generator.predict([imgs_A,imgs_Base]) \n",
    "        re_A = np.squeeze(self.generator_r.predict([fake_B,imgs_cycle]))\n",
    "        \n",
    "        #提取边缘\n",
    "        edge_B = self.edge.predict(fake_B)\n",
    "        B_edge = self.edge.predict(imgs_B)\n",
    "        edge_imgs = np.squeeze(np.concatenate([edge_B, B_edge]))\n",
    "        edge_imgs = 0.5 * edge_imgs + 0.5\n",
    "        \n",
    "        imgs_A = np.squeeze(imgs_A)\n",
    "        imgs_B = np.squeeze(imgs_B)\n",
    "        imgs_Base = np.squeeze(imgs_Base)\n",
    "        imgs_cycle = np.squeeze(imgs_cycle)\n",
    "        fake_B = np.squeeze(fake_B)\n",
    "        \n",
    "        gen_imgs = np.concatenate([imgs_A, imgs_Base, fake_B, imgs_B])\n",
    "\n",
    "        # 重整图片到0-1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Style', 'Content', 'Generated',  'Original']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt], cmap='gray')\n",
    "                axs[i,j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s_bf/%d_%d.png\" % (self.dataset_name, epoch , batch_i))\n",
    "        plt.close()\n",
    "        \n",
    "        #循环重建效果\n",
    "        re_imgs = np.concatenate([fake_B, imgs_cycle, re_A, imgs_A])\n",
    "        #re_imgs = 0.5 * re_imgs + 0.5\n",
    "\n",
    "        titles_r = ['Generated', 'Content', 'Rebuild',  'Original']\n",
    "        fig_r, axs_r = plt.subplots(r, c)\n",
    "        cnt_r = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs_r[i,j].imshow(re_imgs[cnt_r], cmap='gray')\n",
    "                axs_r[i,j].set_title(titles_r[i])\n",
    "                axs_r[i,j].axis('off')\n",
    "                cnt_r += 1\n",
    "        fig_r.savefig(\"images/%s_bf_r/%d_%d.png\" % (self.dataset_name, epoch , batch_i))\n",
    "        plt.close()\n",
    "        \n",
    "        # 边缘控制效果图\n",
    "        fig_e, axs_e = plt.subplots(2, c)\n",
    "        cnt_e = 0\n",
    "        for i in range(2):\n",
    "            for j in range(c):\n",
    "                axs_e[i,j].imshow(edge_imgs[cnt_e], cmap='gray')\n",
    "                axs_e[i,j].axis('off')\n",
    "                cnt_e += 1\n",
    "        fig_e.savefig(\"images/%s_bf_out/%d_%d.png\" % (self.dataset_name, epoch , batch_i))\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        #固定logo测试集\n",
    "        adi_font = np.squeeze(self.generator.predict([self.adidas_,self.imgs]))\n",
    "        nike_font = np.squeeze(self.generator.predict([self.nike_,self.imgs]))\n",
    "        huawei_font = np.squeeze(self.generator.predict([self.huawei_,self.imgs]))\n",
    "        \n",
    "        # adidas样本集 \n",
    "        fig_adi, axs_adi = plt.subplots(5, 6)\n",
    "        cnt_adi = 0\n",
    "        for a in range(5):\n",
    "            for d in range(6):\n",
    "                if cnt_adi < 26:\n",
    "                    axs_adi[a, d].imshow(adi_font[cnt_adi], cmap='gray')\n",
    "                axs_adi[a, d].axis('off')\n",
    "                cnt_adi += 1\n",
    "        fig_adi.savefig(\"images/%s_bf_adi/%d_%d.png\" % (self.dataset_name, epoch , batch_i))\n",
    "        plt.close() \n",
    "        \n",
    "        # nike样本集 \n",
    "        fig_nike, axs_nike = plt.subplots(5, 6)\n",
    "        cnt_nike = 0\n",
    "        for n in range(5):\n",
    "            for k in range(6):\n",
    "                if cnt_nike < 26:\n",
    "                    axs_nike[n,k].imshow(nike_font[cnt_nike], cmap='gray')\n",
    "                axs_nike[n,k].axis('off')\n",
    "                cnt_nike += 1\n",
    "        fig_nike.savefig(\"images/%s_bf_nike/%d_%d.png\" % (self.dataset_name, epoch , batch_i))\n",
    "        plt.close() \n",
    "        \n",
    "        # huawei样本集 \n",
    "        fig_hua, axs_hua = plt.subplots(5, 6)\n",
    "        cnt_hua = 0\n",
    "        for h in range(5):\n",
    "            for w in range(6):\n",
    "                if cnt_hua < 26:\n",
    "                    axs_hua[h,w].imshow(huawei_font[cnt_hua], cmap='gray')\n",
    "                axs_hua[h,w].axis('off')\n",
    "                cnt_hua += 1\n",
    "        fig_hua.savefig(\"images/%s_bf_huawei/%d_%d.png\" % (self.dataset_name, epoch , batch_i))\n",
    "        plt.close() \n",
    "        \n",
    "    def showlogs(self, logs, epoch):\n",
    "        os.makedirs('images/%s_bf_log' % self.dataset_name, exist_ok=True)\n",
    "        logs = np.array(logs)\n",
    "        names = [\"d_loss\", \"d_acc\", \"g_loss\"]\n",
    "        for i in range(3):\n",
    "            plt.subplot(2, 2, i + 1)\n",
    "            plt.plot(logs[:, 0], logs[:, i + 1])\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.ylabel(names[i])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"images/%s_bf_log/%d.png\" % (self.dataset_name, epoch))\n",
    "        plt.close()\n",
    "        \n",
    "                                          \n",
    "if __name__ == '__main__':\n",
    "    dualcgan = Logo2Font()\n",
    "    dualcgan.train(epochs=441, batch_size=10, sample_interval=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
